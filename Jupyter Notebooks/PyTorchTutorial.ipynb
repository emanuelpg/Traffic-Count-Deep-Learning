{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526fa91b-ddef-4a2c-9001-bd4f3080f7a9",
   "metadata": {},
   "source": [
    "# Learning PyTorch with Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3c154-ef70-4451-bee9-52e9ac8eb19d",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34dc69-9473-401c-b3dc-6d1932c6d1a1",
   "metadata": {},
   "source": [
    "### Warm-up Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4972e3e-7300-4361-8995-941f8f546b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d5d00d-d480-461a-995c-2730364fd224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2932.727550468763\n",
      "199 1984.8080274591046\n",
      "299 1345.5554617458304\n",
      "399 914.0458853943688\n",
      "499 622.4801262682479\n",
      "599 425.27354981348924\n",
      "699 291.75085567798465\n",
      "799 201.25120398810375\n",
      "899 139.8459723970504\n",
      "999 98.13616929138729\n",
      "1099 69.77318427976725\n",
      "1199 50.4645077572468\n",
      "1299 37.30485086267191\n",
      "1399 28.32577273952717\n",
      "1499 22.19215668872163\n",
      "1599 17.997460875558094\n",
      "1699 15.125466003892214\n",
      "1799 13.156830763413055\n",
      "1899 11.805868477542944\n",
      "1999 10.87772649396241\n",
      "Result: y = -0.03794718289642867 + 0.8296735978350522x + 0.0065465204934829204x^2 + -0.08948030910903447x^3\n",
      "Execution time: 0.32587099075317383\n"
     ]
    }
   ],
   "source": [
    "# Create input and output data\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Randomly intialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "start = time.time()\n",
    "for t in range(2000):\n",
    "    # Foward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x**2 + d * x**3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x**2).sum()\n",
    "    grad_d = (grad_y_pred * x**3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Result: y = {a} + {b}x + {c}x^2 + {d}x^3\")\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b2b7d-d8cb-4bd6-a61c-fdd2defde59b",
   "metadata": {},
   "source": [
    "### PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea49300-4823-42e1-8980-88c49e8864a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a097de09-3295-4d56-9592-2c5adf3d0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2178.083251953125\n",
      "199 1469.6435546875\n",
      "299 993.4724731445312\n",
      "399 673.1423950195312\n",
      "499 457.4585266113281\n",
      "599 312.1025695800781\n",
      "699 214.0500946044922\n",
      "799 147.843017578125\n",
      "899 103.09439086914062\n",
      "999 72.81845092773438\n",
      "1099 52.31305694580078\n",
      "1199 38.410369873046875\n",
      "1299 28.974037170410156\n",
      "1399 22.562240600585938\n",
      "1499 18.200740814208984\n",
      "1599 15.230567932128906\n",
      "1699 13.205599784851074\n",
      "1799 11.82345962524414\n",
      "1899 10.878966331481934\n",
      "1999 10.232831954956055\n",
      "Result: y = 0.02989010140299797 + 0.8325701951980591 x + -0.00515653844922781 x^2 + -0.08989232033491135 x^3\n",
      "Execution time: 0.2824528217315674\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Create input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights \n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "start = time.time()\n",
    "for t in range(2000):\n",
    "    # Foward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x**2 + d * x**3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "end = time.time()\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114dc350-1b62-4e1c-8b51-eef657861869",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b250ff8-f74d-4c35-9b60-49b2f3cf623a",
   "metadata": {},
   "source": [
    "### PyTorch: tensors and autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79fdda2-f99a-448f-81e9-a0a6c130077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e142d7-8654-42b2-aefd-5a9a89727de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1286.6337890625\n",
      "199 859.4053955078125\n",
      "299 575.2542114257812\n",
      "399 386.194091796875\n",
      "499 260.3535461425781\n",
      "599 176.55799865722656\n",
      "699 120.73539733886719\n",
      "799 83.5302734375\n",
      "899 58.72169876098633\n",
      "999 42.170711517333984\n",
      "1099 31.122879028320312\n",
      "1199 23.74423599243164\n",
      "1299 18.813232421875\n",
      "1399 15.515870094299316\n",
      "1499 13.309537887573242\n",
      "1599 11.832205772399902\n",
      "1699 10.842317581176758\n",
      "1799 10.178573608398438\n",
      "1899 9.733172416687012\n",
      "1999 9.43402099609375\n",
      "Result: y = -0.0138046033680439 + 0.8361940383911133 x + 0.0023815250024199486 x^2 + -0.09040778130292892 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b891f-8607-4a52-90e8-b2bf6a4307ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
